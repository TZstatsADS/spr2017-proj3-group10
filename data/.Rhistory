par(mar=c(4, 11, 2, 2))
beeswarm(word.count~FileOrdered,
data=sentence.list.sel,
horizontal = TRUE,
pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6),
cex=0.55, cex.axis=0.8, cex.lab=0.8,
spacing=5/nlevels(sentence.list.sel$FileOrdered),
las=2, ylab="", xlab="Number of words in a sentence.",
main="Inaugural Speeches")
par(mar=c(4, 11, 2, 2))
#sel.comparison=levels(sentence.list$FileOrdered)
sentence.list.sel=filter(sentence.list,
type=="nomin", Term==2, File%in%sel.comparison)
sentence.list.sel$File=factor(sentence.list.sel$File)
sentence.list.sel$FileOrdered=reorder(sentence.list.sel$File,
sentence.list.sel$word.count,
mean,
order=T)
beeswarm(word.count~FileOrdered,
data=sentence.list.sel,
horizontal = TRUE,
pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6),
cex=0.55, cex.axis=0.8, cex.lab=0.8,
spacing=1.2/nlevels(sentence.list.sel$FileOrdered),
las=2, xlab="Number of words in a sentence.", ylab="",
main="Nomination speeches, 2nd term")
par(mar=c(4, 11, 2, 2))
#sel.comparison=levels(sentence.list$FileOrdered)
sentence.list.sel=filter(sentence.list,
type=="nomin", Term==1, File%in%sel.comparison)
sentence.list.sel$File=factor(sentence.list.sel$File)
sentence.list.sel$FileOrdered=reorder(sentence.list.sel$File,
sentence.list.sel$word.count,
mean,
order=T)
beeswarm(word.count~FileOrdered,
data=sentence.list.sel,
horizontal = TRUE,
pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6),
cex=0.55, cex.axis=0.8, cex.lab=0.8,
spacing=5/nlevels(sentence.list.sel$FileOrdered),
las=2, xlab="Number of words in a sentence.", ylab="",
main="Nomination speeches")
source('C:/Users/sh355/Desktop/R-Tutorials-master/sentiment_cloud.r')
source('C:/Users/sh355/Desktop/R-Tutorials-master/sentiment_cloud.r')
source('C:/Users/sh355/Desktop/R-Tutorials-master/sentiment_cloud.r')
source('C:/Users/sh355/Desktop/R-Tutorials-master/sentiment_cloud.r')
install.packages("twitteR")
source('C:/Users/sh355/Desktop/R-Tutorials-master/sentiment_cloud.r', echo=TRUE)
source('C:/Users/sh355/Desktop/R-Tutorials-master/sentiment_cloud.r', echo=TRUE)
install.packages("twitteR")
tweets = searchTwitter(keyword, n, lang="en")
source('C:/Users/sh355/Desktop/R-Tutorials-master/sentiment_cloud.r', echo=TRUE)
source('C:/Users/sh355/Desktop/R-Tutorials-master/sentiment_cloud.r', echo=TRUE)
install.packages("twitteR")
source('C:/Users/sh355/Desktop/R-Tutorials-master/sentiment_cloud.r', echo=TRUE)
source('C:/Users/sh355/Desktop/R-Tutorials-master/sentiment_cloud.r', echo=TRUE)
install.packages("twitteR")
source('C:/Users/sh355/Desktop/R-Tutorials-master/sentiment_cloud.r', echo=TRUE)
source('C:/Users/sh355/Desktop/R-Tutorials-master/sentiment_cloud.r', echo=TRUE)
install.packages("twitteR")
source('C:/Users/sh355/Desktop/R-Tutorials-master/sentiment_cloud.r', echo=TRUE)
source('C:/Users/sh355/Desktop/R-Tutorials-master/sentiment_cloud.r', echo=TRUE)
install.packages("twitteR")
library("RJSONIO")
library(stringr)
install.packages("RJSONIO")
library("RJSONIO")
source('C:/Users/sh355/Desktop/R-Tutorials-master/sentiment_cloud.r')
install.packages("RJSONIO")
source('C:/Users/sh355/Desktop/R-Tutorials-master/sentiment_cloud.r')
install.packages("twitteR")
install.packages("RJSONIO")
library(twitteR)
library(RCurl)
library("RJSONIO")
library(stringr)
library(tm)
library(wordcloud)
reqURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "http://api.twitter.com/oauth/access_token"
authURL <- "http://api.twitter.com/oauth/authorize"
consumerKey <- "8H7vd7SA1w5Eh2TWSvmYz8Eky"
consumerSecret <- "gEhIsvRW9k2Jxsu107q7SukVz6cIuuOUW3PXxaye5N52Hzlu3I"
twitCred <- OAuthFactory$new(consumerKey=consumerKey,consumerSecret=consumerSecret,requestURL=reqURL,accessURL=accessURL,authURL=authURL)
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
twitCred$handshake(cainfo="cacert.pem")
registerTwitterOAuth(twitCred)
install.packages("twitteR")
install.packages("twitteR")
install.packages("RJSONIO")
library(twitteR)
library(RCurl)
library("RJSONIO")
library(stringr)
library(tm)
library(wordcloud)
reqURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "http://api.twitter.com/oauth/access_token"
authURL <- "http://api.twitter.com/oauth/authorize"
consumerKey <- "8H7vd7SA1w5Eh2TWSvmYz8Eky"
consumerSecret <- "gEhIsvRW9k2Jxsu107q7SukVz6cIuuOUW3PXxaye5N52Hzlu3I"
twitCred <- OAuthFactory$new(consumerKey=consumerKey,consumerSecret=consumerSecret,requestURL=reqURL,accessURL=accessURL,authURL=authURL)
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
twitCred$handshake(cainfo="cacert.pem")
registerTwitterOAuth(twitCred)
install.packages("twitteR")
install.packages("sentiment")
install.packages("twitteR")
install.packages("twitteR")
install.packages("sentiment")
install.packages("plyr")
install.packages("ggplot2")
install.packages("wordcloud")
install.packages("RColorBrewer")
install.packages("Rstem")
install.packages("tm")
install.packages("tm")
install.packages("tm")
install.packages("tm")
install.packages("tm")
install.packages("tm")
install.packages("twitteR")
install.packages("sentiment")
install.packages("plyr")
install.packages("ggplot2")
install.packages("wordcloud")
install.packages("RColorBrewer")
install.packages("Rstem")
install.packages("tm")
install.packages("tm")
library(twitteR)
library(wordcloud)
library(RColorBrewer)
library(plyr)
library(ggplot2)
library(sentiment)
install.packages("sentiment")
install.packages("sentiment")
install.packages("sentiment")
install.packages("plyr")
install.packages("plyr")
install.packages("sentiment")
install.packages("twitteR")
install.packages("plyr")
install.packages("ggplot2")
install.packages("wordcloud")
install.packages("RColorBrewer")
install.packages("Rstem")
install.packages("tm")
library(twitteR)
library(wordcloud)
library(RColorBrewer)
library(plyr)
library(ggplot2)
library(Rstem)
library(tm)
install.packages("devtools")
library(devtools)
install_github('sentiment140', 'okugami79')
library(sentiment)
library(httr)
oauth_endpoints(“twitter”)
library(httr)
oauth_endpoints(“twitter”)
load("twitter authentication.Rdata")
setup_twitter_oauth(8H7vd7SA1w5Eh2TWSvmYz8Eky,gEhIsvRW9k2Jxsu107q7SukVz6cIuuOUW3PXxaye5N52Hzlu3I,726705657827590144-aC6Zl73vOjmV1MJbX0NVPhnUxlsq38N,	rn1h8f92xFX8TTjnIKblk8nbuxm1Ief3mEn0d7FRe4sXq)
setup_twitter_oauth("8H7vd7SA1w5Eh2TWSvmYz8Eky","gEhIsvRW9k2Jxsu107q7SukVz6cIuuOUW3PXxaye5N52Hzlu3I","726705657827590144-aC6Zl73vOjmV1MJbX0NVPhnUxlsq38N",	"rn1h8f92xFX8TTjnIKblk8nbuxm1Ief3mEn0d7FRe4sXq")
tweets = searchTwitter("iphone", 20, lang="en")
tweets = searchTwitter("iphone", 20, lang="en")
tweet_txt = sapply(tweets, function(x) x$getText())
tweet_clean = clean.text(tweet_txt)
tweet_num = length(tweet_clean)
tweet_df = data.frame(text=tweet_clean, sentiment=rep("", tweet_num),stringsAsFactors=FALSE)
sentiment = rep(0, tweet_num)
for (i in 1:tweet_num)
{
tmp = getSentiment(tweet_clean[i], db_key)
tweet_df$sentiment[i] = tmp$sentiment
print(paste(i," of ", tweet_num))
}
library(RCurl)
library("RJSONIO")
install.packages("RJSONIO")
library(RCurl)
library(RJSONIO)
library(stringr)
sentiment = rep(0, tweet_num)
for (i in 1:tweet_num)
{
tmp = getSentiment(tweet_clean[i], db_key)
tweet_df$sentiment[i] = tmp$sentiment
print(paste(i," of ", tweet_num))
}
bjp_tweets = searchTwitter(“BJP”, n=2000, lang=”en”)
bjp_tweets = searchTwitter(“BJP”, n=2000, lang=”en”)
bjp_tweets = searchTwitter("BJP", n=2000, lang=”en”)
bjp_tweets = searchTwitter("BJP", n=2000, lang="en")
bjp_txt = sapply(bjp_tweets, function(x) x$getText())
bjp_txt = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", bjp_txt)
# Then remove all “@people”
bjp_txt = gsub("@\\w+", "", bjp_txt)
# Then remove all the punctuation
bjp_txt = gsub("[[:punct:]]", "", bjp_txt)
# Then remove numbers, we need only text for analytics
bjp_txt = gsub("[[:digit:]]", "", bjp_txt)
# the remove html links, which are not required for sentiment analysis
bjp_txt = gsub("http\\w+", "", bjp_txt)
# finally, we remove unnecessary spaces (white spaces, tabs etc)
bjp_txt = gsub("[ \t]{2,}", "", bjp_txt)
bjp_txt = gsub("^\\s+|\\s+$", "", bjp_txt)
catch.error = function(x)
catch.error = function(x)
{
# let us create a missing value for test purpose
y = NA
# try to catch that error (NA) we just created
catch_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(catch_error, “error”))
catch.error = function(x)
{
# let us create a missing value for test purpose
y = NA
# try to catch that error (NA) we just created
catch_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(catch_error, "error"))
y = tolower(x)
# check result if error exists, otherwise the function works fine.
return(y)
}
bjp_txt = sapply(bjp_txt, catch.error)
bjp_txt = bjp_txt[!is.na(bjp_txt)]
names(bjp_txt) = NULL
bjp_class_emo = classify_emotion(bjp_txt, algorithm=”bayes”, prior=1.0)
names(bjp_txt) = NULL
bjp_class_emo = classify_emotion(bjp_txt, algorithm="bayes", prior=1.0)
library(devtools)
install_github('sentiment140', 'okugami79')
library(sentiment)
library(devtools)
install_github('sentiment140', 'okugami79', force=TRUE)
library(sentiment)
names(bjp_txt) = NULL
bjp_class_emo = classify_emotion(bjp_txt, algorithm="bayes", prior=1.0)
library(devtools)
install_github('sentiment140', 'okugami79', force=TRUE)
library(sentiment)
names(bjp_txt) = NULL
bjp_class_emo = classify_emotion(bjp_txt, algorithm="bayes", prior=1.0)
View(sentence.list)
setup_twitter_oauth("8H7vd7SA1w5Eh2TWSvmYz8Eky","gEhIsvRW9k2Jxsu107q7SukVz6cIuuOUW3PXxaye5N52Hzlu3I","726705657827590144-aC6Zl73vOjmV1MJbX0NVPhnUxlsq38N",	"rn1h8f92xFX8TTjnIKblk8nbuxm1Ief3mEn0d7FRe4sXq")
# get some tweets
tweets = searchTwitter("iphone", 20, lang="en")
# get text
tweet_txt = sapply(tweets, function(x) x$getText())
# clean text
tweet_clean = clean.text(tweet_txt)
tweet_num = length(tweet_clean)
# data frame (text, sentiment)
tweet_df = data.frame(text=tweet_clean, sentiment=rep("", tweet_num),stringsAsFactors=FALSE)
# apply function getSentiment
sentiment = rep(0, tweet_num)
for (i in 1:tweet_num)
{
tmp = getSentiment(tweet_clean[i], "8H7vd7SA1w5Eh2TWSvmYz8Eky")
tweet_df$sentiment[i] = tmp$sentiment
print(paste(i," of ", tweet_num))
}
# apply function getSentiment
sentiment = rep(0, tweet_num)
for (i in 1:tweet_num)
{
tmp = getSentiment(tweet_clean[i], "8H7vd7SA1w5Eh2TWSvmYz8Eky")
tweet_df$sentiment[i] = tmp$sentiment
print(paste(i," of ", tweet_num))
}
getSentiment <- function (text, key){
text <- URLencode(text);
#save all the spaces, then get rid of the weird characters that break the API, then convert back the URL-encoded spaces.
text <- str_replace_all(text, "%20", " ");
text <- str_replace_all(text, "%\\d\\d", "");
text <- str_replace_all(text, " ", "%20");
if (str_length(text) > 360){
text <- substr(text, 0, 359);
}
getSentiment <- function (text, key){
text <- URLencode(text);
#save all the spaces, then get rid of the weird characters that break the API, then convert back the URL-encoded spaces.
text <- str_replace_all(text, "%20", " ");
text <- str_replace_all(text, "%\\d\\d", "");
text <- str_replace_all(text, " ", "%20");
if (str_length(text) > 360){
text <- substr(text, 0, 359);
}
getSentiment <- function (text, key){
text <- URLencode(text);
#save all the spaces, then get rid of the weird characters that break the API, then convert back the URL-encoded spaces.
text <- str_replace_all(text, "%20", " ");
text <- str_replace_all(text, "%\\d\\d", "");
text <- str_replace_all(text, " ", "%20");
if (str_length(text) > 360){
text <- substr(text, 0, 359);
}}
data <- getURL(paste("http://api.datumbox.com/1.0/TwitterSentimentAnalysis.json?api_key=", key, "&text=",text, sep=""))
data <- getURL(paste("http://api.datumbox.com/1.0/TwitterSentimentAnalysis.json?api_key=	8H7vd7SA1w5Eh2TWSvmYz8Eky", key, "&text=",text, sep=""))
data <- getURL(paste("http://api.datumbox.com/1.0/TwitterSentimentAnalysis.json?8H7vd7SA1w5Eh2TWSvmYz8Eky", key, "&text=",text, sep=""))
getSentiment <- function (text, key){
text <- URLencode(text);
#save all the spaces, then get rid of the weird characters that break the API, then convert back the URL-encoded spaces.
text <- str_replace_all(text, "%20", " ");
text <- str_replace_all(text, "%\\d\\d", "");
text <- str_replace_all(text, " ", "%20");
if (str_length(text) > 360){
text <- substr(text, 0, 359);
}
data <- getURL(paste("http://api.datumbox.com/1.0/TwitterSentimentAnalysis.json?api_key=", key, "&text=",text, sep=""))
js <- fromJSON(data, asText=TRUE);
# get mood probability
sentiment = js$output$result
return(list(sentiment=sentiment))
}
getSentiment <- function (text, key){
text <- URLencode(text);
#save all the spaces, then get rid of the weird characters that break the API, then convert back the URL-encoded spaces.
text <- str_replace_all(text, "%20", " ");
text <- str_replace_all(text, "%\\d\\d", "");
text <- str_replace_all(text, " ", "%20");
if (str_length(text) > 360){
text <- substr(text, 0, 359);
}
data <- getURL(paste("http://api.datumbox.com/1.0/TwitterSentimentAnalysis.json?api_key=", key, "&text=",text, sep=""))
js <- fromJSON(data, asText=TRUE);
# get mood probability
sentiment = js$output$result
return(list(sentiment=sentiment))
}
clean.text <- function(some_txt)
{
some_txt = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", some_txt)
some_txt = gsub("@\\w+", "", some_txt)
some_txt = gsub("[[:punct:]]", "", some_txt)
some_txt = gsub("[[:digit:]]", "", some_txt)
some_txt = gsub("http\\w+", "", some_txt)
some_txt = gsub("[ \t]{2,}", "", some_txt)
some_txt = gsub("^\\s+|\\s+$", "", some_txt)
some_txt = gsub("amp", "", some_txt)
# define "tolower error handling" function
try.tolower = function(x)
{
y = NA
try_error = tryCatch(tolower(x), error=function(e) e)
if (!inherits(try_error, "error"))
y = tolower(x)
return(y)
}
some_txt = sapply(some_txt, try.tolower)
some_txt = some_txt[some_txt != ""]
names(some_txt) = NULL
return(some_txt)
}
# get some tweets
tweets = searchTwitter("iphone", 20, lang="en")
# get text
tweet_txt = sapply(tweets, function(x) x$getText())
# clean text
tweet_clean = clean.text(tweet_txt)
tweet_num = length(tweet_clean)
# data frame (text, sentiment)
tweet_df = data.frame(text=tweet_clean, sentiment=rep("", tweet_num),stringsAsFactors=FALSE)
# apply function getSentiment
sentiment = rep(0, tweet_num)
for (i in 1:tweet_num)
{
tmp = getSentiment(tweet_clean[i], db_key)
tweet_df$sentiment[i] = tmp$sentiment
print(paste(i," of ", tweet_num))
}
# apply function getSentiment
sentiment = rep(0, tweet_num)
for (i in 1:tweet_num)
{
tmp = getSentiment(tweet_clean[i], "8H7vd7SA1w5Eh2TWSvmYz8Eky")
tweet_df$sentiment[i] = tmp$sentiment
print(paste(i," of ", tweet_num))
}
# apply function getSentiment
sentiment = rep(0, tweet_num)
for (i in 1:tweet_num)
{
tmp = getSentiment(tweet_clean[i], "8H7vd7SA1w5Eh2TWSvmYz8Eky")
tweet_df$sentiment[i] = tmp$sentiment
print(paste(i," of ", tweet_num))
}
# apply function getSentiment
sentiment = rep(0, tweet_num)
for (i in 1:tweet_num)
{
tmp = getSentiment(tweet_clean[i], "8H7vd7SA1w5Eh2TWSvmYz8Eky")
tweet_df$sentiment[i] = tmp$sentiment
print(paste(i," of ", tweet_num))
}
bjp_tweets = searchTwitter(“BJP”, n=2000, lang=”en”)
bjp_tweets = searchTwitter("BJP", n=2000, lang="en")
bjp_txt = sapply(bjp_tweets, function(x) x$getText())
bjp_txt = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", bjp_txt)
bjp_txt = gsub("@\\w+", "“”", bjp_txt)
bjp_txt = gsub("[[:punct:]]", "", bjp_txt)
bjp_txt = gsub("[[:digit:]]", "", bjp_txt)
bjp_txt = gsub("http\\w+", "", bjp_txt)
bjp_txt = gsub("[ \t]{2,}", "", bjp_txt)
bjp_txt = gsub("^\\s+|\\s+$", "", bjp_txt)
catch.error = function(x)
{
# let us create a missing value for test purpose
y = NA
# try to catch that error (NA) we just created
catch_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(catch_error, “error”))
catch.error = function(x)
{
# let us create a missing value for test purpose
y = NA
# try to catch that error (NA) we just created
catch_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(catch_error, "error"))
y = tolower(x)
# check result if error exists, otherwise the function works fine.
return(y)
}
bjp_txt = sapply(bjp_txt, catch.error)
bjp_txt = bjp_txt[!is.na(bjp_txt)]
names(bjp_txt) = NULL
classify_emotion <- function(textColumns,algorithm="bayes",prior=1.0,verbose=FALSE,...) {
matrix <- create_matrix(textColumns,...)
lexicon <- read.csv(system.file("data/emotions.csv.gz",package="sentiment"),header=FALSE)
counts <- list(anger=length(which(lexicon[,2]=="anger")),disgust=length(which(lexicon[,2]=="disgust")),fear=length(which(lexicon[,2]=="fear")),joy=length(which(lexicon[,2]=="joy")),sadness=length(which(lexicon[,2]=="sadness")),surprise=length(which(lexicon[,2]=="surprise")),total=nrow(lexicon))
documents <- c()
for (i in 1:nrow(matrix)) {
if (verbose) print(paste("DOCUMENT",i))
scores <- list(anger=0,disgust=0,fear=0,joy=0,sadness=0,surprise=0)
doc <- matrix[i,]
words <- findFreqTerms(doc,lowfreq=1)
for (word in words) {
for (key in names(scores)) {
emotions <- lexicon[which(lexicon[,2]==key),]
index <- pmatch(word,emotions[,1],nomatch=0)
if (index > 0) {
entry <- emotions[index,]
category <- as.character(entry[[2]])
count <- counts[[category]]
score <- 1.0
if (algorithm=="bayes") score <- abs(log(score*prior/count))
if (verbose) {
print(paste("WORD:",word,"CAT:",category,"SCORE:",score))
}
scores[[category]] <- scores[[category]]+score
}
}
}
if (algorithm=="bayes") {
for (key in names(scores)) {
count <- counts[[key]]
total <- counts[["total"]]
score <- abs(log(count/total))
scores[[key]] <- scores[[key]]+score
}
} else {
for (key in names(scores)) {
scores[[key]] <- scores[[key]]+0.000001
}
}
best_fit <- names(scores)[which.max(unlist(scores))]
if (best_fit == "disgust" && as.numeric(unlist(scores[2]))-3.09234 < .01) best_fit <- NA
documents <- rbind(documents,c(scores$anger,scores$disgust,scores$fear,scores$joy,scores$sadness,scores$surprise,best_fit))
}
colnames(documents) <- c("ANGER","DISGUST","FEAR","JOY","SADNESS","SURPRISE","BEST_FIT")
return(documents)
}
bjp_class_emo = classify_emotion(bjp_txt, algorithm=”bayes”, prior=1.0)
bjp_class_emo = classify_emotion(bjp_txt, algorithm="bayes", prior=1.0)
?pnorm
pnorm(1, mean = 0.001, sd=0.015, log.p = TRUE)
1000*pnorm(1, mean = 0.001, sd=0.015, log.p = TRUE)
1000*pnorm(1, mean = 0.001, sd=0.015, log.p = TRUE)
pnorm(10, mean = 0.001, sd=0.015, log.p = TRUE)
pnorm(10, mean = 0.001, sd=0.015, log.p = TRUE)
pnorm(1/365, mean = 0.001, sd=0.015, log.p = TRUE)
pnorm(exp(-10), mean = 0.001, sd=0.015, log.p = TRUE)
pnorm(exp(-10), mean = 0.001, sd=0.015)
length()
length
?length
ln(1000/828)
log(1000/828)
log(1000/828)/5
845.3538-828
(845.3538-828)/828
21/0.02+（1000-21/0.02)*1.02^(-20)
tper<-function(){}
tper<-function(t,y){m=(t-y)/y;return(m)}
tper(1000, 969.9321)
tper(854.8042, 888.9964)
tper(692.5108, 810.1743)
tper(933.5107, 888.9964)
tper(848.2603, 810.1743)
setwd("~/GitHub/spr2017-proj3-group10/data")
load("siftFeatures.RData")
edit(sift_features)
